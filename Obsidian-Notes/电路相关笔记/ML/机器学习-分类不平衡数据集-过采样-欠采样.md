#### 一、创建分类不平衡的数据集及进行可视化：

##### 1、所需API：

from sklearn.datasets import make_classification  
import matplotlib.pyplot as plt  
from collections import Counter

##### 2、代码演示🌰：使用make_classification生成样本数据

```python
from sklearn.datasets import make_classification
import matplotlib.pyplot as plt
from collections import Counter

# 1.创建类别不平衡的数据集：
# 使用make_classification生成样本数据
X, y = make_classification(n_samples=5000,
                           n_features=2,  # 特征个数 = n_informative() + n_redundant + n_repeated
                           n_informative=2,  # 多信息特征的个数
                           n_redundant=0,  # 冗余信息，informative特征的随机线性组合
                           n_repeated=0,  # 重复信息，随机提取n_informative和n_redundant 特征
                           n_classes=3,  # 分类类别
                           n_clusters_per_class=1,  # 某一个类别是有几个cluster构成的
                           weights=[0.01, 0.05, 0.94],  # 列表类型，权重比
                           random_state=0
                           )

# 2.查看各个标签的样本：
counter = Counter(y)
print(counter) # Counter({2: 4674, 1: 262, 0: 64})

# 3.数据集可视化：
plt.scatter(X[:, 0], X[:, 1], c=y)
plt.show()

```

##### 3、运行结果:
![[Pasted image 20220512093519.png]]
![](//upload-images.jianshu.io/upload_images/6909373-94e13415111170ce.png?imageMogr2/auto-orient/strip|imageView2/2/w/1138/format/webp)

运行结果:.png

#### 二、过采样和欠采样

##### 1、过采样方法：

对训练集里的少数类进行“过采样”(oversampling),既增加一些少数类样本🙆正、反例数目接近，然后再进行学习。

###### 1.1、随机过采样方法：

-   方法：随机过采样是在少数类_Smin_中随机选择一些样本，然后通过复制所选择的样本生成样本集E，将他们添加到_Smin_中扩大原始数据集从而得到新的少数类集合_Snew-min_。新数据集_Snew-min=Smin + E_。
    
-   API：from imblearn.over_sampling import RandomOverSampler
    
-   代码演示🌰：
    

```python
from sklearn.datasets import make_classification
import matplotlib.pyplot as plt
from collections import Counter
from imblearn.over_sampling import RandomOverSampler

# 1.创建类别不平衡的数据集：
# 使用make_classification生成样本数据
X, y = make_classification(n_samples=5000,
                           n_features=2,  # 特征个数 = n_informative() + n_redundant + n_repeated
                           n_informative=2,  # 多信息特征的个数
                           n_redundant=0,  # 冗余信息，informative特征的随机线性组合
                           n_repeated=0,  # 重复信息，随机提取n_informative和n_redundant 特征
                           n_classes=3,  # 分类类别
                           n_clusters_per_class=1,  # 某一个类别是有几个cluster构成的
                           weights=[0.01, 0.05, 0.94],  # 列表类型，权重比
                           random_state=0
                           )

# 2.查看各个标签的样本：
counter = Counter(y)
print(counter)  # Counter({2: 4674, 1: 262, 0: 64})

# 3.数据集可视化：
plt.scatter(X[:, 0], X[:, 1], c=y)
plt.show()

# 4、过采样 
# 4.1 随机过采样
ros = RandomOverSampler(random_state=0)

X_resampled, y_resampled = ros.fit_resample(X, y)
counter_resampled = Counter(y_resampled)
print(counter_resampled)

plt.scatter(X_resampled[:, 0], X_resampled[:, 1], c=y_resampled)
plt.show()

```

-   随机过采样运行结果：

![](//upload-images.jianshu.io/upload_images/6909373-dbe5100997ac9d90.png?imageMogr2/auto-orient/strip|imageView2/2/w/1108/format/webp)

随机过采样运行结果.png

-   **随机过采样的缺点：**  
    （1）对于随机过采样，由于需要对少数类样本进行复制来扩大数据集，造成模型训练复杂度加大。  
    （2）另一方面也容易造成模型的过拟合问题，因为随机过采样是简单的对初始样本进行复制采样，这就使得学习器学得的规则过于具体化，不利于学习器的泛化性能，造成过拟合问题。  
    （3）为了解决随机过采样中造成模型过拟合问题，又能保证实现数据集均衡的目的，出现了过采样法代表性的算法**SMOTE算法**。

##### 1.2、SMOTE算法(过采样代表性算法)：

**1.2.1、**SMOTE全称是Synthetic Minority Oversampling即合成少数类过采样技术。是对随机过采样方法的一个改进算法，由于随机过采样方法是直接对少数类进行重采用，会使训练集中有很多重复的样本，容易造成产生的模型过拟合问题。

###### 而SMOTE算法的基本思想：对每个少数类样本 _xi_ ，从它的最近邻中随机选择一个样本 _x̅i (即x拔)_, _x̅i_ 是少数类中的一个样本，然后在 _xi_ 和 _x̅i_ 之间的连线上随机选择一个点作为新合成的少数样本类。

**1.2.2、**SMOTE算法合成新少数类样本的算法过程：  
（1）对少数类中的每一个样本_xi_，以欧式距离为标准计算它到少数类样本集_Smin_中所有样本的距离，得到其k近邻。  
（2）根据样本不平衡比例设置一个采样比例以确定采样倍率N，对于每一个少数类样本 _xi_ ，从其k近邻中随机选择若干个样本，假设选择的是 _x̅i_。  
（3）对于每一个随机选择出来的近邻 _x̅i_ ，分别与 _xi_ 按照如下公式构建新的样本。

###### _Xnew = Xi + rand(0, 1) × (x̅i - Xi)_

**1.2.3、图文表达方式：**

（1）先随机选定一个少数类样本 _Xi_。

![](//upload-images.jianshu.io/upload_images/6909373-6a3ece31f8443ab0.png?imageMogr2/auto-orient/strip|imageView2/2/w/354/format/webp)

1.png

（2）找出这个少数类样本 _Xi_ 的K个近邻(假设K=5)，5个近邻已经被圈出。

![](//upload-images.jianshu.io/upload_images/6909373-69b5604a1b569dc1.png?imageMogr2/auto-orient/strip|imageView2/2/w/330/format/webp)

2.png

（3）随机从这K个近邻中选择一个样本 _x̅i_ (用绿色圈出来了)。

![](//upload-images.jianshu.io/upload_images/6909373-72bc6a267f1b5237.png?imageMogr2/auto-orient/strip|imageView2/2/w/330/format/webp)

3.png

（4）在少数类样本 _Xi_ 和被选中的这个近邻样本 _x̅i_ 之间的连线上，随机找一点。这个点就是人工合成的新的样本点(绿色正号标出)。

![](//upload-images.jianshu.io/upload_images/6909373-9afaac72888c8cd0.png?imageMogr2/auto-orient/strip|imageView2/2/w/332/format/webp)

4.png

##### SMOTE算法摒弃了随机过采样复制样本的做法，可以防止随机过采样中容易过拟合的问题，实践证明此方法可以提高分类器的性能。

**1.2.4、SMOTE算法API：from imblearn.over_sampling import SMOTE**

**1.2.5、SMOTE算法代码实现🌰：**

```python
from sklearn.datasets import make_classification
import matplotlib.pyplot as plt
from collections import Counter
from imblearn.over_sampling import RandomOverSampler, SMOTE
from imblearn.under_sampling import RandomUnderSampler

# 1.创建类别不平衡的数据集：
# 使用make_classification生成样本数据
X, y = make_classification(n_samples=5000,
                           n_features=2,  # 特征个数 = n_informative() + n_redundant + n_repeated
                           n_informative=2,  # 多信息特征的个数
                           n_redundant=0,  # 冗余信息，informative特征的随机线性组合
                           n_repeated=0,  # 重复信息，随机提取n_informative和n_redundant 特征
                           n_classes=3,  # 分类类别
                           n_clusters_per_class=1,  # 某一个类别是有几个cluster构成的
                           weights=[0.01, 0.05, 0.94],  # 列表类型，权重比
                           random_state=0
                           )

# 2.查看各个标签的样本：
counter = Counter(y)
print(counter)  # Counter({2: 4674, 1: 262, 0: 64})

# 3.数据集可视化：
plt.scatter(X[:, 0], X[:, 1], c=y)
plt.show()

# 4、过采样
# 4.1 随机过采样
ros = RandomOverSampler(random_state=0)

X_resampled, y_resampled = ros.fit_resample(X, y)
counter_resampled = Counter(y_resampled)
print(counter_resampled)

plt.scatter(X_resampled[:, 0], X_resampled[:, 1], c=y_resampled)
plt.show()

# 4.2 SMOTE过采样
X_resampled2, y_resampled2 = SMOTE().fit_resample(X, y)
counter_resampled2 = Counter(y_resampled2)
print("SMOTE过采样结果：\n", counter_resampled2)

plt.scatter(X_resampled2[:, 0], X_resampled2[:, 1], c=y_resampled2)
plt.show()

```

**1.2.6、SMOTE过采样运行结果：**

![](//upload-images.jianshu.io/upload_images/6909373-caa8361bbe31daf3.png?imageMogr2/auto-orient/strip|imageView2/2/w/1168/format/webp)

SMOTE过采样运行结果.png

##### 2、欠采样方法：

**2.1、什么是欠采样方法：**

直接对训练集中多数类样本进行“欠采样”(undersampling),即**去除一些多数类中的样本使得正例、反例数目接近，然后再进行学习。**

**2.2、随机欠采样方法：**

###### 随机欠采样即从多数类 _Smaj_ 中随机选择一些样本组成样本集 _E_ 。然后将样本集 _E_ 从 _Smaj_ 中移除。新的数据集 _Snew-maj = Smaj - E_。

**2.3、随机欠采样方法缺点：**  
随机欠采样方法通过改变多数类样本比例以达到修改样本分布的目的，从而使样本分布较为均衡，但是这也存在一些问题。对于随机欠采样，**由于采样的样本集合要少于原来的样本集合，因此会造成一些信息缺失，即将多数类样本删除有可能会导致分类器丢失有关多数类的重要信息。**

**2.4、随机欠采样方法的代码实现🌰：**

```python
from sklearn.datasets import make_classification
import matplotlib.pyplot as plt
from collections import Counter
from imblearn.over_sampling import RandomOverSampler, SMOTE
from imblearn.under_sampling import RandomUnderSampler

# 1.创建类别不平衡的数据集：
# 使用make_classification生成样本数据
X, y = make_classification(n_samples=5000,
                           n_features=2,  # 特征个数 = n_informative() + n_redundant + n_repeated
                           n_informative=2,  # 多信息特征的个数
                           n_redundant=0,  # 冗余信息，informative特征的随机线性组合
                           n_repeated=0,  # 重复信息，随机提取n_informative和n_redundant 特征
                           n_classes=3,  # 分类类别
                           n_clusters_per_class=1,  # 某一个类别是有几个cluster构成的
                           weights=[0.01, 0.05, 0.94],  # 列表类型，权重比
                           random_state=0
                           )

# 2.查看各个标签的样本：
counter = Counter(y)
print(counter)  # Counter({2: 4674, 1: 262, 0: 64})

# 3.数据集可视化：
plt.scatter(X[:, 0], X[:, 1], c=y)
plt.show()

# 4、过采样
# 4.1 随机过采样
ros = RandomOverSampler(random_state=0)

X_resampled, y_resampled = ros.fit_resample(X, y)
counter_resampled = Counter(y_resampled)
print(counter_resampled)

plt.scatter(X_resampled[:, 0], X_resampled[:, 1], c=y_resampled)
plt.show()

# 4.2 SMOTE过采样
X_resampled2, y_resampled2 = SMOTE().fit_resample(X, y)
counter_resampled2 = Counter(y_resampled2)
print("SMOTE过采样结果：\n", counter_resampled2)

plt.scatter(X_resampled2[:, 0], X_resampled2[:, 1], c=y_resampled2)
plt.show()

# 5、欠采样
# 5.1 随机欠采样
rus = RandomUnderSampler(random_state=0)

X_resampled_u1, y_resampled_u1 = rus.fit_resample(X, y)
counter_resampled_u1 = Counter(y_resampled_u1)
print("随机欠采样结果:\n", counter_resampled_u1)

plt.scatter(X_resampled_u1[:, 0], X_resampled_u1[:, 1], c=y_resampled_u1)
plt.show()

```

**2.5、随机欠采样方法的运行结果：**

![](//upload-images.jianshu.io/upload_images/6909373-9b3c47fce7859b32.png?imageMogr2/auto-orient/strip|imageView2/2/w/1174/format/webp)

2.5.png

  
  
作者：涓涓自然卷  
链接：https://www.jianshu.com/p/b24c3177ea47  
来源：简书  
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。