# physics-informed neural network

#### what is a physics-informed neural network

One way to do this for our problem is to use a _physics-informed neural network_. 
The idea is very simple:

- **add the known differential equations directly into the loss function**  when training the neural network.


This is done by sampling a set of input training locations (![\{x_{j}\}](https://benmoseley.blog/wp-content/ql-cache/quicklatex.com-478addca9753a25592833af65a2797da_l3.svg "Rendered by QuickLaTeX.com")) and passing them through the network. Next gradients of the network’s output with respect to its input are computed at these locations (which are typically analytically available for most neural networks, and can be easily computed using [autodifferentiation](https://en.wikipedia.org/wiki/Automatic_differentiation)). Finally, the residual of the underlying differential equation is computed using these gradients, and added as an extra term in the loss function.

[![](https://benmoseley.blog/wp-content/uploads/2021/08/pinn-1024x405.png)](https://benmoseley.blog/wp-content/uploads/2021/08/pinn.png)

Fig 4: schematic of physics-informed neural network

Let’s do this for the problem above. This amounts to using the following loss function to train the network:  
![[Pasted image 20220602021327.png]]
$$
\begin{align}
\mathrm{min} & {\frac{1}{N}} \sum^{N}_{i}(u_{\mathrm{NN}}(x_{i};\theta) - u_{\mathrm{true}}(x_i) )^2 \\[2ex]
& + \frac{1}{M} \sum^{M}_{j} \left( \left[ m\frac{d^2}{dx^2} + \mu \frac{d}{dx} + k \right] u_{\mathrm{NN}}(x_{j};\theta)  \right)^2 
\end{align}
$$

We can see that the additional “physics loss” in the loss function tries to ensure that the solution learned by the network is consistent with the known physics.

And here’s the result when we train the physics-informed network:

[![](https://benmoseley.blog/wp-content/uploads/2021/08/pinn.gif)](https://benmoseley.blog/wp-content/uploads/2021/08/pinn.gif)

Fig 5: a physics-informed neural network learning to model a harmonic oscillator

#### Remarks

The physics-informed neural network is able to predict the solution far away from the experimental data points, and thus performs much better than the naive network. One could argue that this network does indeed have some concept of our prior physical principles.

The naive network is performing poorly because we are “throwing away” our existing scientific knowledge; with only the data at hand, it is like trying to understand all of the data generated by a particle collider, without having been to a physics class!

Whilst we focused on a specific physics problem here, physics-informed neural networks can be easily applied to many other types of differential equations too, and are a general-purpose tool for incorporating physics into machine learning.

#### Conclusion
